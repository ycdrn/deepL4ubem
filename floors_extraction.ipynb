{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning-Based WWR and Floor Count Extraction from Fa√ßade Images to Improve UBEM\n",
    "\n",
    "CISBAT 2025\n",
    "\n",
    "[Ayca Duran](https://systems.arch.ethz.ch/ayca-duran), [Panagiotis Karapiperis](https://www.linkedin.com/in/panagiotis-karapiperis-ethz/), [Christoph Waibel](https://systems.arch.ethz.ch/christoph-waibel), [Arno Schlueter](https://systems.arch.ethz.ch/arno-schlueter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLOOR COUNT Extraction Workflow\n",
    "\n",
    "This notebook performs the floor count extraction using the rectified images and feature masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "import matplotlib.patches as patches\n",
    "from scipy.cluster.hierarchy import fcluster, linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set Paths\n",
    "images_path = \"example/rectified/images\"\n",
    "facade_predictions_path = \"example/rectified/facades\"\n",
    "window_predictions_path_original = \"example/predictions/fcn_resnet50_rectified\"\n",
    "window_predictions_path_gsam = \"example/predictions/gsam_rectified\"\n",
    "\n",
    "# Save Paths\n",
    "figs_save_path = \"example/FLOORS/floors_detection\"\n",
    "floors_path = \"example/FLOORS/floors.csv\"\n",
    "\n",
    "os.makedirs(figs_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_white_rows_top_bottom(image):\n",
    "    \"\"\"\n",
    "    Counts how many completely white rows are at the top and bottom of an image.\n",
    "    Assumes image is a NumPy array (H, W) or (H, W, C) with white = 255.\n",
    "    Returns (top_count, bottom_count)\n",
    "    \"\"\"\n",
    "    # If image has 3 channels, reduce along the channel axis\n",
    "    if image.ndim == 3:\n",
    "        white_mask = np.all(image == 255, axis=2)\n",
    "    else:\n",
    "        white_mask = image == 255\n",
    "\n",
    "    # Count white rows from top\n",
    "    top_count = next((i for i, row in enumerate(white_mask) if not np.all(row)), len(white_mask))\n",
    "\n",
    "    # Count white rows from bottom\n",
    "    bottom_count = next((i for i, row in enumerate(reversed(white_mask)) if not np.all(row)), len(white_mask))\n",
    "\n",
    "    return top_count, bottom_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_black_with_white(image):\n",
    "    \n",
    "    # Create a mask for black pixels\n",
    "    black_pixels = np.all(image <= [8, 8, 8], axis=-1)\n",
    "    \n",
    "    # Replace black pixels with white\n",
    "    image[black_pixels] = [255, 255, 255]\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to fix the clustering of the windows to go from top to bottom\n",
    "def reassign_cluster_labels(clusters):\n",
    "    return_clusters = []\n",
    "    return_clusters.append(1)\n",
    "    index = 1\n",
    "    for i in range(1,len(clusters)):\n",
    "        if clusters[i] == clusters[i-1]:\n",
    "            return_clusters.append(index)\n",
    "        else:\n",
    "            index = index+1\n",
    "            return_clusters.append(index)\n",
    "    return_clusters = np.array(return_clusters)\n",
    "    return return_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop FLOOR Count Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame with the defined columns\n",
    "columns = ['filename'] + ['FLOORS']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Iterate\n",
    "for filename in os.listdir(images_path):\n",
    "\n",
    "    # Load img & masks\n",
    "    img=cv2.imread(os.path.join(images_path, filename))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    facade_prediction = cv2.imread(os.path.join(facade_predictions_path, filename.split(\".\")[0]+\".png\"), cv2.IMREAD_GRAYSCALE)\n",
    "    window_prediction_fcn = cv2.imread(os.path.join(window_predictions_path_original, filename.split(\".\")[0]+\".png\"), cv2.IMREAD_GRAYSCALE)\n",
    "    window_prediction_gsam = cv2.imread(os.path.join(window_predictions_path_gsam, filename.split(\".\")[0]+\".png\"), cv2.IMREAD_GRAYSCALE)\n",
    "    window_prediction = np.logical_or(window_prediction_fcn, window_prediction_gsam).astype(np.uint8)\n",
    "\n",
    "    # Crop left & Rights\n",
    "    y_indices, x_indices = np.where(facade_prediction > 0)\n",
    "    x_min, x_max = x_indices.min(), x_indices.max()\n",
    "\n",
    "    cropped_img = img[:, x_min:x_max+1]\n",
    "    cropped_facade = facade_prediction[:, x_min:x_max+1]\n",
    "    cropped_windows = window_prediction[:, x_min:x_max+1]\n",
    "\n",
    "    # Remove top & bottom white rows\n",
    "    cropped_img = replace_black_with_white(cropped_img)\n",
    "    num_white_top, num_white_bottom = count_white_rows_top_bottom(cropped_img)\n",
    "    cropped_img = cropped_img[num_white_top:cropped_img.shape[0] - num_white_bottom,:]\n",
    "    cropped_facade = cropped_facade[num_white_top:cropped_facade.shape[0] - num_white_bottom,:]\n",
    "    cropped_windows = cropped_windows[num_white_top:cropped_windows.shape[0] - num_white_bottom,:]\n",
    "\n",
    "    # Prepare\n",
    "    # Remove small blobs from rectified window predictions\n",
    "    kernel1 = np.ones((5, 5), np.uint8)  # Kernel size can be adjusted\n",
    "    cropped_windows = cv2.morphologyEx(cropped_windows, cv2.MORPH_OPEN, kernel1)\n",
    "\n",
    "    ### Identify instances of windows with connected components\n",
    "    num_labels_per, labels_per = cv2.connectedComponents(cropped_windows)\n",
    "    unique_labels_per = np.unique(labels_per)\n",
    "    unique_labels_per = unique_labels_per[unique_labels_per != 0]\n",
    "    # Count distinct regions\n",
    "    # Note: num_labels includes the background as label 0, so subtract 1 for the count of class 1 regions\n",
    "    num_instances_per = num_labels_per - 1\n",
    "    #print(num_instances)\n",
    "\n",
    "    # Visualize rectified image and facade / windows predictions\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 10), sharex=True)\n",
    "    axes[0].imshow(cropped_img)\n",
    "    axes[0].set_title(f\"Image {filename}\")\n",
    "    axes[0].grid(False)\n",
    "    \n",
    "    ### Find uppermost Point for each window\n",
    "    windows_uppermost_points = {}\n",
    "    for label in unique_labels_per:\n",
    "        class_positions = np.argwhere(labels_per == label)\n",
    "        uppermost_pixel = class_positions[np.argmin(class_positions[:, 0])]\n",
    "        windows_uppermost_points[label] = tuple(uppermost_pixel)\n",
    "\n",
    "    # Extract points as a NumPy array\n",
    "    points_per = np.array(list(windows_uppermost_points.values()))\n",
    "    if len(points_per) <= 1:\n",
    "        continue\n",
    "    # Use only the first coordinate (row) for clustering\n",
    "    rows_per = points_per[:, 0].reshape(-1, 1)\n",
    "    # Perform hierarchical clustering\n",
    "    linked_per = linkage(rows_per, method='ward') \n",
    "    clusters_per = fcluster(linked_per, t=70, criterion='distance')  # t=50 defines max distance between clusters\n",
    "    ## Sort clusters to ensure starting from top to bottom\n",
    "    clusters_per = reassign_cluster_labels(clusters_per)\n",
    "\n",
    "    # Group points by clusters\n",
    "    clustered_points_per = {}\n",
    "    for idx, cluster_id in enumerate(clusters_per):\n",
    "        clustered_points_per.setdefault(cluster_id, []).append(list(windows_uppermost_points.values())[idx])\n",
    "\n",
    "    # Group windows with clusters\n",
    "    # Initialize a new mask with the same shape as the `labels` array\n",
    "    clustered_mask_per = np.zeros_like(labels_per)\n",
    "    # Map each instance label in `labels` to its cluster index\n",
    "    for instance_label, cluster_index in enumerate(clusters_per, start=1):  # start=1 to match labels\n",
    "        clustered_mask_per[labels_per == instance_label] = cluster_index   # +1 to keep 0 for background\n",
    "    axes[1].imshow(cropped_facade, cmap=\"rainbow\", alpha= 0.5)\n",
    "    axes[1].imshow(clustered_mask_per, cmap=\"rainbow\", alpha= 0.5)\n",
    "    axes[1].set_title(f\"Windows Clustered in {len(np.unique(clusters_per))} Floors\")\n",
    "    axes[1].grid(False)\n",
    "\n",
    "    # Plot the uppermost points\n",
    "    for label, uppermost_pixel in windows_uppermost_points.items():\n",
    "        y, x = uppermost_pixel\n",
    "        axes[1].plot(x, y, \"bo\")  \n",
    "        axes[1].text(x + 5, y, f\"Window {label}\", color=\"white\", fontsize=10, bbox=dict(facecolor='black', alpha=0.5))\n",
    "    \n",
    "    # Visualize Floors\n",
    "    mask = clustered_mask_per.astype(np.uint8)\n",
    "    output = np.zeros_like(mask, dtype=np.uint8)\n",
    "    \n",
    "    # Loop over each cluster\n",
    "    for cluster_id in np.unique(mask):\n",
    "        if cluster_id == 0:\n",
    "            continue  # skip background\n",
    "\n",
    "        # Extract only this cluster\n",
    "        cluster_mask = (mask == cluster_id).astype(np.uint8)\n",
    "        # Label connected blobs within this cluster\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(cluster_mask, connectivity=8)\n",
    "        # Skip background (label 0)\n",
    "        centroids = centroids[1:]\n",
    "        # Sort centroids left-to-right by x coordinate\n",
    "        centroids = sorted(centroids, key=lambda c: c[0])\n",
    "        axes[2].scatter(*zip(*centroids))\n",
    "        # Convert to int tuple points for cv2.polylines\n",
    "        pts = np.array(centroids, dtype=np.int32).reshape(-1, 1, 2)\n",
    "        # Draw polyline connecting the blobs for this cluster\n",
    "        if len(pts) > 1:\n",
    "            cv2.polylines(output, [pts], isClosed=False, color=int(cluster_id), thickness=5)\n",
    "        \n",
    "        mid_idx = len(centroids) // 2\n",
    "        mid_x, mid_y = map(int, centroids[mid_idx])\n",
    "        label = f\"Floor {cluster_id}\"\n",
    "        color=int(cluster_id)\n",
    "        axes[2].text(mid_x + 10, mid_y - 10, label, color='white', fontsize=16, bbox=dict(facecolor='black', alpha=0.2))\n",
    "\n",
    "    axes[2].imshow(cropped_img)\n",
    "    axes[2].imshow(cropped_windows, cmap=\"gray\", alpha=0.5)\n",
    "    axes[2].imshow(output, cmap=\"rainbow\", alpha=0.6)\n",
    "    axes[2].set_title(\"Floors Visualization\")\n",
    "    plt.savefig(os.path.join(figs_save_path, filename), dpi=300, bbox_inches='tight') # Save clustered windows fig\n",
    "    plt.close()\n",
    "\n",
    "    # Store results in DataFrame\n",
    "    row = {'filename': filename, 'FLOORS': len(np.unique(clusters_per))}\n",
    "    df.loc[len(df)] = row\n",
    "    #break\n",
    "\n",
    "# Save Results to CSV\n",
    "df.to_csv(floors_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
